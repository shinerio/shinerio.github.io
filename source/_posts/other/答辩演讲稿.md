Part One

本科就读于北京科技大学，保研至北京邮电大学，获得多个奖项，包括阿里巴巴天池比赛的冠军以及coco关键点挑战赛的全球第三名

 Part Two

来阿里的第一个任务是中间件的学习，我将以meta的消息存储为例来介绍我的学习成果。metaQ的消息主要是按topic区分存储于broker节点上。metaQ在写消息和读消息方面都做了高吞吐量的保证。对于写消息来说，meta所有的消息都是存储到commit log文件中的，顺序写磁盘效率比随机写内存还高。对用户展示的逻辑队列只存消息在commit log中的偏移量，采用串行化刷盘，降低了iowait。consumer读取消息首先从consumer queue中读取偏移量，然后利用偏移量快速定位消息在commit log中的位置。consumer queue文件比较小，只存了索引信息，因此consumer读取consumer queue可以采用page cache缓存技术。对于commit log文件的读取，利用NIO提供的FileChannel模型，将磁盘物理文件映射到用户态内存中，使用零拷贝的方式，减少了传统IO将磁盘文件在内核态和用户之间来回拷贝的性能开销。但是内存映射的局限之一就是一次只能映射1.5~2G文件值用户态的虚拟内存，因此rocketMQ默认设置commit log文件大小为1G。 metaQ相比与kafka来说，吞吐量其实还是有一定的差距，主要还是其面向业务场景不同。kafka主要面向日志记录，其对消息消费成功率要求不高。kafka在producer端对小消息的聚合，不支持事务和检索功能。kafka的每个topic都会单独维护commit log，高并发的写请求导致kafka的队列或者分区数不可能太高。

metaQ作为一个消息中间件，其主要解决的是业务解耦、异步调用和流量削峰问题。2C订单库存分配链路作为大宝库存域的核心链路之一就用到了metaQ。库存域的操作主要包括三个环节，接单、一级账的占用以及二三级账的占用。最简单的设计方案就是每个环境直接通过metaQ进行交互，占用采用消息自发自收的方式。这样做的优点是实现比较简单，不同环节间的流量负载均衡可以由metaQ天然支持。但是同时也有比较明显的缺点，业务追踪困难，无法实现对sku进行聚合占用的优化，导致行锁问题严重，这个主要体现在一个包裹包括多个sku，由于某个sku可能被不同线程处理，导致多线程之间并发争抢这条sku的行锁。针对这些问题，库存系统自己设计了一套排队分类引擎作为解决方案。gis与上游系统之间接单仍然通过metaQ进行解耦。对于gis内部的库存占用逻辑，采用了二级分流+二级排队的模型。一级分流保证同一sku被分到同一个hash桶中，后续只会被一台机器处理。目前的方案还存在一些弊端，对于爆品sku，由于分流策略会被同时打到某台机器上，极端情况下某台机器同时处理多个爆品sku，出现严重的负载不均衡。我有一个不太成熟的思考方案是建立一个爆品sku名单机制，对于这部分sku爆品可以根据各个redis桶的score情况，绕过hash直接分配到压力较小的桶中，定时去扫描爆名单，将其从名单中移除。

Part three

