# 1. [deepseek](https://github.com/deepseek-ai/DeepSeek-V3)
|    **Model**     | **#Total Params** | **#Activated Params** | **Context Length** |
| :--------------: | :---------------: | :-------------------: | :----------------: |
| DeepSeek-V3-Base |       671B        |          37B          |        128K        |
|   DeepSeek-V3    |       671B        |          37B          |        128K        |

é‡‡ç”¨MOE(Mixture-of-Expertsï¼Œæ··åˆä¸“å®¶)æ¶æ„ï¼Œå¤§æ¨¡å‹æœ‰671Bå‚æ•°ï¼Œä½†æ˜¯å®é™…æ¯æ¬¡æ¨ç†åªä½¿ç”¨37Bçš„å‚æ•°

DeepSeek-R1 Model

|    **Model**     | **#Total Params** | **#Activated Params** | **Context Length** |                             **Download**                              |
| :--------------: | :---------------: | :-------------------: | :----------------: | :-------------------------------------------------------------------: |
| DeepSeek-R1-Zero |       671B        |          37B          |        128K        | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero) |
|   DeepSeek-R1    |       671B        |          37B          |        128K        |   [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1)    |

DeepSeek-R1-Distill Models

|**Model**|**Base Model**|**Download**|
|:-:|:-:|:-:|
|DeepSeek-R1-Distill-Qwen-1.5B|[Qwen2.5-Math-1.5B](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B)|[ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)|
|DeepSeek-R1-Distill-Qwen-7B|[Qwen2.5-Math-7B](https://huggingface.co/Qwen/Qwen2.5-Math-7B)|[ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)|
|DeepSeek-R1-Distill-Llama-8B|[Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B)|[ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)|
|DeepSeek-R1-Distill-Qwen-14B|[Qwen2.5-14B](https://huggingface.co/Qwen/Qwen2.5-14B)|[ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)|
|DeepSeek-R1-Distill-Qwen-32B|[Qwen2.5-32B](https://huggingface.co/Qwen/Qwen2.5-32B)|[ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B)|
|DeepSeek-R1-Distill-Llama-70B|[Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)|[ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B)|

> å•†ä¸šå‹å¥½ï¼Œå…è®¸å…è´¹å•†ç”¨
# 2. Google Gemma

# 3. Mistral & Mixtral

# 4. [kimi-k2](https://github.com/MoonshotAI/Kimi-K2?tab=readme-ov-file)


| **Architecture**                            | Mixture-of-Experts (MoE) |
| ------------------------------------------- | ------------------------ |
| **Total Parameters**                        | 1T                       |
| **Activated Parameters**                    | 32B                      |
| **Number of Layers**Â (Dense layer included) | 61                       |
| **Number of Dense Layers**                  | 1                        |
| **Attention Hidden Dimension**              | 7168                     |
| **MoE Hidden Dimension**Â (per Expert)       | 2048                     |
| **Number of Attention Heads**               | 64                       |
| **Number of Experts**                       | 384                      |
| **Selected Experts per Token**              | 8                        |
| **Number of Shared Experts**                | 1                        |
| **Vocabulary Size**                         | 160K                     |
| **Context Length**                          | 128K                     |
| **Attention Mechanism**                     | MLA                      |
| **Activation Function**                     | SwiGLU                   |
éµå¾ªå®½æ¾çš„MITåè®®ï¼Œåšäº†å¦‚ä¸‹ä¿®æ”¹
- **è§¦å‘æ¡ä»¶ï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰**ï¼š
    1. ä½ çš„å•†ä¸šäº§å“æˆ–æœåŠ¡æœˆæ´»è·ƒç”¨æˆ·ï¼ˆMAUï¼‰è¶…è¿‡ **1 äº¿**ï¼›   
    2. æˆ–è€…ä½ çš„å•†ä¸šäº§å“æˆ–æœåŠ¡æœˆæ”¶å…¥è¶…è¿‡ **2000 ä¸‡ç¾å…ƒ**ï¼ˆæˆ–ç­‰å€¼è´§å¸ï¼‰ã€‚
- **å¼ºåˆ¶ä¹‰åŠ¡**ï¼š å¦‚æœè¾¾åˆ°ä¸Šè¿°è§„æ¨¡ï¼Œä½ å¿…é¡»åœ¨äº§å“æˆ–æœåŠ¡çš„ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰æ˜¾è‘—ä½ç½®å±•ç¤º **â€œKimi K2â€** å­—æ ·ã€‚
# 5. Qwen

| Model     | Release Date | Max Length | System Prompt Enhancement | # of Pretrained Tokens | Minimum GPU Memory Usage of Finetuning (Q-Lora) | Minimum GPU Usage of Generating 2048 Tokens (Int4) | Tool Usage |
| :-------- | :----------: | :--------: | :-----------------------: | :--------------------: | :---------------------------------------------: | :------------------------------------------------: | :--------: |
| Qwen-1.8B |   23.11.30   |    32K     |             âœ…             |          2.2T          |                      5.8GB                      |                       2.9GB                        |     âœ…      |
| Qwen-7B   |   23.08.03   |    32K     |             â             |          2.4T          |                     11.5GB                      |                       8.2GB                        |     âœ…      |
| Qwen-14B  |   23.09.25   |     8K     |             â             |          3.0T          |                     18.7GB                      |                       13.0GB                       |     âœ…      |
| Qwen-72B  |   23.11.30   |    32K     |             âœ…             |          3.0T          |                     61.4GB                      |                       48.9GB                       |     âœ…      |

> å•†ç”¨å‹å¥½
# 6. Meta Llama

|    **Model**     | **Launch date** |         **Model sizes**          | **Context Length** | **Tokenizer**  |                                    **Acceptable use policy**                                     |                                       **License**                                       |                                             **Model Card**                                              |
| :--------------: | :-------------: | :------------------------------: | :----------------: | :------------: | :----------------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------: |
|     Llama 2      |    7/18/2023    |           7B, 13B, 70B           |         4K         | Sentencepiece  |  [Use Policy](https://github.com/meta-llama/llama-models/blob/main/models/llama2/USE_POLICY.md)  |  [License](https://github.com/meta-llama/llama-models/blob/main/models/llama2/LICENSE)  |     [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama2/MODEL_CARD.md)      |
|     Llama 3      |    4/18/2024    |             8B, 70B              |         8K         | TikToken-based |  [Use Policy](https://github.com/meta-llama/llama-models/blob/main/models/llama3/USE_POLICY.md)  |  [License](https://github.com/meta-llama/llama-models/blob/main/models/llama3/LICENSE)  |     [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3/MODEL_CARD.md)      |
|    Llama 3.1     |    7/23/2024    |          8B, 70B, 405B           |        128K        | TikToken-based | [Use Policy](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/USE_POLICY.md) | [License](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE) |    [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)     |
|    Llama 3.2     |    9/25/2024    |              1B, 3B              |        128K        | TikToken-based | [Use Policy](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md) | [License](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE) |    [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md)     |
| Llama 3.2-Vision |    9/25/2024    |             11B, 90B             |        128K        | TikToken-based | [Use Policy](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md) | [License](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE) | [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md) |
|    Llama 3.3     |   12/04/2024    |               70B                |        128K        | TikToken-based | [Use Policy](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/USE_POLICY.md) | [License](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE) |    [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)     |
|     Llama 4      |    4/5/2025     | Scout-17B-16E, Maverick-17B-128E |      10M, 1M       | TikToken-based |  [Use Policy](https://github.com/meta-llama/llama-models/blob/main/models/llama4/USE_POLICY.md)  |  [License](https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE)  |     [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama4/MODEL_CARD.md)      |

> licenseå—é™ï¼Œæœˆæ´»ç”¨æˆ·è¶…è¿‡7äº¿ä¸å…è®¸ä½¿ç”¨ã€‚Additional Commercial Terms. If, on the Llama 4 version release date, the monthly active users of the products or services made available by or for Licensee, or Licenseeâ€™s affiliates, is greater than 700 million monthly active users in the preceding calendar month, you must request a license from Meta, which Meta may grant to you in its sole discretion, and you are not authorized to exercise any of the rights under this Agreement unless or until Meta otherwise expressly grants you such rights